{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_v1_Cocoa.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjxtuGL5DCQlVwXrSwBeIi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sulfika715/DeepLearning/blob/master/Inception_v1_Cocoa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSN8YB-xB6Y7",
        "colab_type": "code",
        "outputId": "36b0cae0-091c-4961-d06a-4c3b3e04873e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZjFVfA8CFP9",
        "colab_type": "code",
        "outputId": "4779c620-7fb3-4eca-af27-32b9dc0c5624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/'My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Dc5ABKCNkL",
        "colab_type": "code",
        "outputId": "0b90b0f0-72a0-4f10-dfee-7d808b86c7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDJ4yGfoCUcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = './Dataset/'\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f56ck23mCdLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV8sgRiOCjDH",
        "colab_type": "code",
        "outputId": "846f3c6d-5223-4fa7-fc28-a09c2e99e849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Moldy_Cocoa ...\n",
            "[INFO] Processing Broken_Beans_Cocoa ...\n",
            "[INFO] Processing Fermented_Cocoa ...\n",
            "[INFO] Processing Unfermented_Cocoa ...\n",
            "[INFO] Processing Bean_Fraction_Cocoa ...\n",
            "[INFO] Processing Whole_Beans_Cocoa ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmnAPwg3DcSU",
        "colab_type": "code",
        "outputId": "b77b9bd1-7682-483a-8ea0-c1e77cdc987c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo9sY9fVDfqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpde8o5tDled",
        "colab_type": "code",
        "outputId": "6c40260c-af58-4119-d800-9a278f9ba3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bean_Fraction_Cocoa' 'Broken_Beans_Cocoa' 'Fermented_Cocoa'\n",
            " 'Moldy_Cocoa' 'Unfermented_Cocoa' 'Whole_Beans_Cocoa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_egZSNM-DpIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytjyVe36Dv3R",
        "colab_type": "code",
        "outputId": "0c843a78-703f-4d07-bade-1ef19e0c6ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EACzLFSJD1M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tI5nV6fD-yD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Inception Model\n",
        "\n",
        "# Impor paket yang diperlukan Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Inisialisasi Core\n",
        "kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "# Inisialisasi offset\n",
        "bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "\n",
        "# Fungsi yang menghasilkan Modul Inception\n",
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "\n",
        "    # Konvolusi 1 × 1\n",
        "    conv_1x1 = Conv2D(filters_1x1,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_1x1 = BatchNormalization()(conv_1x1)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3,\n",
        "                      (3, 3),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_3x3)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_5x5)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Max pooling\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk mencerna dimensi maksimum yang dikurangi\n",
        "    pool_proj = Conv2D(filters_pool_proj,\n",
        "                       (1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(pool_proj)\n",
        "    pool_proj = BatchNormalization()(pool_proj)\n",
        "\n",
        "    # Stack merge\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkmuKSLBEIoI",
        "colab_type": "code",
        "outputId": "0dbe0183-135b-49a5-d854-f79bef2e99f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Impor paket yang diperlukan\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Mendefinisikan Inception-V1\n",
        "class GoogleNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, channel, classes):\n",
        "\n",
        "        input_layer = Input(shape=(width, height, channel))\n",
        "\n",
        "        # Inisialisasi inti\n",
        "        kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        # Inisialisasi offset\n",
        "        bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (7, 7),\n",
        "                   padding='same',\n",
        "                   strides=(2, 2),\n",
        "                   activation='relu',\n",
        "                   name='conv_1_7x7/2')(input_layer)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (1, 1),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2a_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(192,\n",
        "                   (3, 3),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2b_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=64,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=128,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=32,\n",
        "                             filters_pool_proj=32,\n",
        "                             name='inception_3a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=192,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=96,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_3b')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=192,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=208,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=48,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=160,\n",
        "                             filters_3x3_reduce=112,\n",
        "                             filters_3x3=224,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4b')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=256,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4c')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=112,\n",
        "                             filters_3x3_reduce=144,\n",
        "                             filters_3x3=288,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4d')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_4e')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=384,\n",
        "                             filters_3x3_reduce=192,\n",
        "                             filters_3x3=384,\n",
        "                             filters_5x5_reduce=48,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5b')\n",
        "\n",
        "        # Global Avarage Pooling\n",
        "        x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "        # Random inactivation\n",
        "        x = Dropout(0.40)(x)\n",
        "\n",
        "        # Full connection/output\n",
        "        x = Dense(classes, activation='softmax', name='output')(x)\n",
        "\n",
        "        # Create GoogleNet model\n",
        "        # return Model(input_layer, [x, x1, x2], name='inception_v1')\n",
        "        return Model(input_layer, x, name='inception_v1')\n",
        "\n",
        "\n",
        "# Test GoogleNet class instantiation and output summary information of GoogleNet model\n",
        "if __name__ == \"__main__\":\n",
        "    model = GoogleNet.build(width=224, height=224, channel=3, classes=6)\n",
        "    print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1_7x7/2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv_1_7x7/2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_1_3x3/2 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_2a_3x3/1 (Conv2D)          (None, 56, 56, 64)   4160        max_pool_1_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv_2a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_2b_3x3/1 (Conv2D)          (None, 56, 56, 192)  110784      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 192)  768         conv_2b_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_3x3/2 (MaxPooling2D) (None, 28, 28, 192)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 96)   18528       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 16)   3088        max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 96)   384         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 28, 28, 192)  0           max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 64)   12352       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  110720      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 32)   12832       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 32)   6176        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 28, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a (Concatenate)      (None, 28, 28, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 32)   8224        inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 192)  221376      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 96)   76896       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 192)  768         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 96)   384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b (Concatenate)      (None, 28, 28, 480)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_3_3x3/2 (MaxPooling2D) (None, 14, 14, 480)  0           inception_3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 96)   46176       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 16)   7696        max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 96)   384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 480)  0           max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 192)  92352       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 208)  179920      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 48)   19248       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 192)  768         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 208)  832         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 48)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 112)  57456       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 24)   12312       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 14, 14, 112)  448         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 24)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 160)  82080       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 224)  226016      batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 14, 14, 160)  640         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 14, 14, 224)  896         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4b (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_21[0][0]     \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 24)   12312       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 14, 14, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 24)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 256)  295168      batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 128)  512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 64)   256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 64)   256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4c (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_27[0][0]     \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 144)  73872       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 32)   16416       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 144)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 112)  57456       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 288)  373536      batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 64)   51264       batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 112)  448         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 288)  1152        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 64)   256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4d (Concatenate)      (None, 14, 14, 528)  0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 160)  84640       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 32)   16928       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 160)  640         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 32)   128         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 528)  0           inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 256)  135424      inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 320)  461120      batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 128)  102528      batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 320)  1280        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e (Concatenate)      (None, 14, 14, 832)  0           batch_normalization_39[0][0]     \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_4_3x3/2 (MaxPooling2D) (None, 7, 7, 832)    0           inception_4e[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 160)    133280      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 32)     26656       max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    640         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 32)     128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 832)    0           max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 256)    213248      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 320)    461120      batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 128)    102528      batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 320)    1280        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 128)    512         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 128)    512         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a (Concatenate)      (None, 7, 7, 832)    0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    159936      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 48)     39984       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 192)    768         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 48)     192         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 832)    0           inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 384)    319872      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 384)    663936      batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 128)    153728      batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 384)    1536        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 384)    1536        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 128)    512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 128)    512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b (Concatenate)      (None, 7, 7, 1024)   0           batch_normalization_51[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool_5_3x3/1 (GlobalAverage (None, 1024)         0           inception_5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           avg_pool_5_3x3/1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 6)            6150        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,008,822\n",
            "Trainable params: 5,994,262\n",
            "Non-trainable params: 14,560\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ9tiPOlETZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2eW84cVEirW",
        "colab_type": "code",
        "outputId": "2c26b920-e6e4-4696-dc02-672da21bf6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    validation_steps=1200// BS,\n",
        "    max_queue_size=BS*2,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "14/15 [===========================>..] - ETA: 1s - loss: 0.4944 - acc: 0.8337Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 2s 18ms/sample - loss: 0.4551 - acc: 0.8333\n",
            "15/15 [==============================] - 26s 2s/step - loss: 0.4847 - acc: 0.8355 - val_loss: 0.4531 - val_acc: 0.8333\n",
            "Epoch 2/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.3619 - acc: 0.8642Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5463 - acc: 0.8333\n",
            "15/15 [==============================] - 6s 371ms/step - loss: 0.3581 - acc: 0.8653 - val_loss: 0.5305 - val_acc: 0.8333\n",
            "Epoch 3/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.3057 - acc: 0.8712Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.6340 - acc: 0.7154\n",
            "15/15 [==============================] - 6s 369ms/step - loss: 0.3051 - acc: 0.8722 - val_loss: 0.6144 - val_acc: 0.7154\n",
            "Epoch 4/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2829 - acc: 0.8806Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.7293 - acc: 0.7209\n",
            "15/15 [==============================] - 6s 379ms/step - loss: 0.2840 - acc: 0.8791 - val_loss: 1.5629 - val_acc: 0.7209\n",
            "Epoch 5/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2571 - acc: 0.8876Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.7306 - acc: 0.7222\n",
            "15/15 [==============================] - 6s 374ms/step - loss: 0.2552 - acc: 0.8878 - val_loss: 0.7121 - val_acc: 0.7222\n",
            "Epoch 6/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2337 - acc: 0.9024Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.1530 - acc: 0.7209\n",
            "15/15 [==============================] - 6s 373ms/step - loss: 0.2349 - acc: 0.9001 - val_loss: 1.0736 - val_acc: 0.7209\n",
            "Epoch 7/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1691 - acc: 0.9304Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 2.1508 - acc: 0.7209\n",
            "15/15 [==============================] - 6s 387ms/step - loss: 0.1719 - acc: 0.9288 - val_loss: 1.9973 - val_acc: 0.7209\n",
            "Epoch 8/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1928 - acc: 0.9212Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.9143 - acc: 0.7615\n",
            "15/15 [==============================] - 6s 371ms/step - loss: 0.1891 - acc: 0.9227 - val_loss: 0.8806 - val_acc: 0.7615\n",
            "Epoch 9/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1901 - acc: 0.9223Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8707 - acc: 0.7453\n",
            "15/15 [==============================] - 6s 370ms/step - loss: 0.1936 - acc: 0.9205 - val_loss: 0.8283 - val_acc: 0.7453\n",
            "Epoch 10/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1548 - acc: 0.9340Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.1750 - acc: 0.7507\n",
            "15/15 [==============================] - 6s 376ms/step - loss: 0.1609 - acc: 0.9332 - val_loss: 1.0798 - val_acc: 0.7507\n",
            "Epoch 11/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2120 - acc: 0.9044Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0630 - acc: 0.7331\n",
            "15/15 [==============================] - 6s 371ms/step - loss: 0.2081 - acc: 0.9078 - val_loss: 1.0499 - val_acc: 0.7331\n",
            "Epoch 12/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1755 - acc: 0.9336Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.6185 - acc: 0.7154\n",
            "15/15 [==============================] - 6s 371ms/step - loss: 0.1717 - acc: 0.9350 - val_loss: 1.5850 - val_acc: 0.7154\n",
            "Epoch 13/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1466 - acc: 0.9477Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.2763 - acc: 0.7412\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.1445 - acc: 0.9473 - val_loss: 1.2490 - val_acc: 0.7412\n",
            "Epoch 14/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1753 - acc: 0.9368Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.6861 - acc: 0.7344\n",
            "15/15 [==============================] - 6s 371ms/step - loss: 0.1722 - acc: 0.9365 - val_loss: 1.5556 - val_acc: 0.7344\n",
            "Epoch 15/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1610 - acc: 0.9375Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 2.0363 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 366ms/step - loss: 0.1560 - acc: 0.9397 - val_loss: 1.9823 - val_acc: 0.7154\n",
            "Epoch 16/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1911 - acc: 0.9239Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.6444 - acc: 0.7317\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.1860 - acc: 0.9263 - val_loss: 1.5325 - val_acc: 0.7317\n",
            "Epoch 17/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1461 - acc: 0.9450Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8695 - acc: 0.7913\n",
            "15/15 [==============================] - 6s 369ms/step - loss: 0.1488 - acc: 0.9426 - val_loss: 0.7664 - val_acc: 0.7913\n",
            "Epoch 18/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1439 - acc: 0.9454Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.3009 - acc: 0.7493\n",
            "15/15 [==============================] - 6s 370ms/step - loss: 0.1456 - acc: 0.9441 - val_loss: 1.2004 - val_acc: 0.7493\n",
            "Epoch 19/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1763 - acc: 0.9200Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.4883 - acc: 0.7737\n",
            "15/15 [==============================] - 6s 389ms/step - loss: 0.1711 - acc: 0.9222 - val_loss: 1.4282 - val_acc: 0.7737\n",
            "Epoch 20/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1548 - acc: 0.9457Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 1s 8ms/sample - loss: 2.4453 - acc: 0.7791\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.1604 - acc: 0.9433 - val_loss: 1.7287 - val_acc: 0.7791\n",
            "Epoch 21/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1830 - acc: 0.9286Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0904 - acc: 0.7751\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.1787 - acc: 0.9299 - val_loss: 0.9994 - val_acc: 0.7751\n",
            "Epoch 22/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1389 - acc: 0.9430Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.1192 - acc: 0.8103\n",
            "15/15 [==============================] - 6s 373ms/step - loss: 0.1369 - acc: 0.9441 - val_loss: 1.1374 - val_acc: 0.8103\n",
            "Epoch 23/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1426 - acc: 0.9431Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.6324 - acc: 0.7696\n",
            "15/15 [==============================] - 6s 386ms/step - loss: 0.1384 - acc: 0.9444 - val_loss: 1.7471 - val_acc: 0.7696\n",
            "Epoch 24/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1476 - acc: 0.9446Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.9759 - acc: 0.7967\n",
            "15/15 [==============================] - 5s 345ms/step - loss: 0.1463 - acc: 0.9441 - val_loss: 0.9973 - val_acc: 0.7967\n",
            "Epoch 25/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1336 - acc: 0.9453Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.2902 - acc: 0.7778\n",
            "15/15 [==============================] - 6s 380ms/step - loss: 0.1342 - acc: 0.9451 - val_loss: 1.2839 - val_acc: 0.7778\n",
            "Epoch 26/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1188 - acc: 0.9512Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5258 - acc: 0.8415\n",
            "15/15 [==============================] - 6s 375ms/step - loss: 0.1163 - acc: 0.9528 - val_loss: 0.5328 - val_acc: 0.8415\n",
            "Epoch 27/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1564 - acc: 0.9438Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4108 - acc: 0.8659\n",
            "15/15 [==============================] - 6s 375ms/step - loss: 0.1509 - acc: 0.9466 - val_loss: 0.3949 - val_acc: 0.8659\n",
            "Epoch 28/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1238 - acc: 0.9512Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.9195 - acc: 0.7588\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.1325 - acc: 0.9488 - val_loss: 1.8578 - val_acc: 0.7588\n",
            "Epoch 29/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1238 - acc: 0.9582Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.4608 - acc: 0.7805\n",
            "15/15 [==============================] - 5s 366ms/step - loss: 0.1218 - acc: 0.9582 - val_loss: 1.4074 - val_acc: 0.7805\n",
            "Epoch 30/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1307 - acc: 0.9489Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8798 - acc: 0.8320\n",
            "15/15 [==============================] - 5s 364ms/step - loss: 0.1284 - acc: 0.9495 - val_loss: 0.8552 - val_acc: 0.8320\n",
            "Epoch 31/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1122 - acc: 0.9512Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.3773 - acc: 0.8686\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.1091 - acc: 0.9528 - val_loss: 0.4063 - val_acc: 0.8686\n",
            "Epoch 32/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1042 - acc: 0.9606Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5914 - acc: 0.8333\n",
            "15/15 [==============================] - 5s 364ms/step - loss: 0.1040 - acc: 0.9601 - val_loss: 0.5857 - val_acc: 0.8333\n",
            "Epoch 33/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1220 - acc: 0.9489Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.1071 - acc: 0.7927\n",
            "15/15 [==============================] - 5s 364ms/step - loss: 0.1232 - acc: 0.9495 - val_loss: 1.0727 - val_acc: 0.7927\n",
            "Epoch 34/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0951 - acc: 0.9649Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.7696 - acc: 0.7791\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.0974 - acc: 0.9641 - val_loss: 0.7626 - val_acc: 0.7791\n",
            "Epoch 35/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1069 - acc: 0.9586Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4306 - acc: 0.8902\n",
            "15/15 [==============================] - 5s 367ms/step - loss: 0.1042 - acc: 0.9597 - val_loss: 0.4173 - val_acc: 0.8902\n",
            "Epoch 36/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0969 - acc: 0.9625Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8435 - acc: 0.8252\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.0972 - acc: 0.9615 - val_loss: 0.7755 - val_acc: 0.8252\n",
            "Epoch 37/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1237 - acc: 0.9501Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 3.7824 - acc: 0.7317\n",
            "15/15 [==============================] - 6s 382ms/step - loss: 0.1210 - acc: 0.9514 - val_loss: 3.9142 - val_acc: 0.7317\n",
            "Epoch 38/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1122 - acc: 0.9520Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 2.0781 - acc: 0.7425\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.1083 - acc: 0.9540 - val_loss: 2.1869 - val_acc: 0.7425\n",
            "Epoch 39/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1130 - acc: 0.9590Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5018 - acc: 0.8550\n",
            "15/15 [==============================] - 5s 359ms/step - loss: 0.1105 - acc: 0.9597 - val_loss: 0.4878 - val_acc: 0.8550\n",
            "Epoch 40/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0949 - acc: 0.9673Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.9800 - acc: 0.8279\n",
            "15/15 [==============================] - 6s 380ms/step - loss: 0.0921 - acc: 0.9681 - val_loss: 0.8344 - val_acc: 0.8279\n",
            "Epoch 41/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1116 - acc: 0.9524Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7777 - acc: 0.7967\n",
            "15/15 [==============================] - 5s 358ms/step - loss: 0.1101 - acc: 0.9528 - val_loss: 0.8209 - val_acc: 0.7967\n",
            "Epoch 42/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2218 - acc: 0.9180Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5647 - acc: 0.8482\n",
            "15/15 [==============================] - 5s 359ms/step - loss: 0.2195 - acc: 0.9176 - val_loss: 0.4991 - val_acc: 0.8482\n",
            "Epoch 43/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1422 - acc: 0.9462Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.2990 - acc: 0.8794\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.1394 - acc: 0.9486 - val_loss: 0.2740 - val_acc: 0.8794\n",
            "Epoch 44/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1009 - acc: 0.9598Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4860 - acc: 0.8631\n",
            "15/15 [==============================] - 6s 373ms/step - loss: 0.1072 - acc: 0.9601 - val_loss: 0.4680 - val_acc: 0.8631\n",
            "Epoch 45/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0898 - acc: 0.9703Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.3869 - acc: 0.8713\n",
            "15/15 [==============================] - 5s 366ms/step - loss: 0.0904 - acc: 0.9695 - val_loss: 0.3916 - val_acc: 0.8713\n",
            "Epoch 46/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1076 - acc: 0.9590Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8312 - acc: 0.8293\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.1027 - acc: 0.9615 - val_loss: 0.8199 - val_acc: 0.8293\n",
            "Epoch 47/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1137 - acc: 0.9582Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5637 - acc: 0.8591\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.1115 - acc: 0.9579 - val_loss: 0.4797 - val_acc: 0.8591\n",
            "Epoch 48/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1025 - acc: 0.9598Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.5312 - acc: 0.8482\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.1066 - acc: 0.9579 - val_loss: 0.5056 - val_acc: 0.8482\n",
            "Epoch 49/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1051 - acc: 0.9606Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.3861 - acc: 0.7967\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.1035 - acc: 0.9615 - val_loss: 1.3531 - val_acc: 0.7967\n",
            "Epoch 50/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1126 - acc: 0.9571Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.6259 - acc: 0.8049\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.1085 - acc: 0.9590 - val_loss: 1.5895 - val_acc: 0.8049\n",
            "Epoch 51/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0878 - acc: 0.9602Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.3113 - acc: 0.9024\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.0862 - acc: 0.9615 - val_loss: 0.2991 - val_acc: 0.9024\n",
            "Epoch 52/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0973 - acc: 0.9621Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.4437 - acc: 0.7751\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0943 - acc: 0.9633 - val_loss: 1.4528 - val_acc: 0.7751\n",
            "Epoch 53/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1295 - acc: 0.9520Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0650 - acc: 0.7913\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.1283 - acc: 0.9513 - val_loss: 0.9554 - val_acc: 0.7913\n",
            "Epoch 54/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1102 - acc: 0.9547Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.1538 - acc: 0.8374\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.1132 - acc: 0.9535 - val_loss: 1.0723 - val_acc: 0.8374\n",
            "Epoch 55/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1024 - acc: 0.9591Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.1062 - acc: 0.8076\n",
            "15/15 [==============================] - 6s 379ms/step - loss: 0.1034 - acc: 0.9590 - val_loss: 1.1066 - val_acc: 0.8076\n",
            "Epoch 56/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0763 - acc: 0.9727Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.8915 - acc: 0.8062\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.0768 - acc: 0.9726 - val_loss: 1.3867 - val_acc: 0.8062\n",
            "Epoch 57/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0773 - acc: 0.9684Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.3632 - acc: 0.7995\n",
            "15/15 [==============================] - 6s 377ms/step - loss: 0.0815 - acc: 0.9674 - val_loss: 1.3944 - val_acc: 0.7995\n",
            "Epoch 58/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0965 - acc: 0.9633Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.3991 - acc: 0.7967\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.1009 - acc: 0.9619 - val_loss: 1.4151 - val_acc: 0.7967\n",
            "Epoch 59/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1028 - acc: 0.9637Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8582 - acc: 0.8455\n",
            "15/15 [==============================] - 6s 368ms/step - loss: 0.1018 - acc: 0.9641 - val_loss: 0.9030 - val_acc: 0.8455\n",
            "Epoch 60/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0812 - acc: 0.9703Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0997 - acc: 0.8347\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.0778 - acc: 0.9717 - val_loss: 1.1626 - val_acc: 0.8347\n",
            "Epoch 61/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0842 - acc: 0.9660Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9527 - acc: 0.8049\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 0.0854 - acc: 0.9666 - val_loss: 0.9859 - val_acc: 0.8049\n",
            "Epoch 62/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9727Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4865 - acc: 0.8659\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0689 - acc: 0.9728 - val_loss: 0.4405 - val_acc: 0.8659\n",
            "Epoch 63/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0955 - acc: 0.9594Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8248 - acc: 0.8442\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.0911 - acc: 0.9619 - val_loss: 0.8164 - val_acc: 0.8442\n",
            "Epoch 64/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1227 - acc: 0.9664Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0934 - acc: 0.8428\n",
            "15/15 [==============================] - 5s 358ms/step - loss: 0.1180 - acc: 0.9666 - val_loss: 1.0730 - val_acc: 0.8428\n",
            "Epoch 65/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1017 - acc: 0.9629Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4010 - acc: 0.8537\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.1044 - acc: 0.9615 - val_loss: 0.4289 - val_acc: 0.8537\n",
            "Epoch 66/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1082 - acc: 0.9539Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.6372 - acc: 0.7778\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.1044 - acc: 0.9561 - val_loss: 1.9703 - val_acc: 0.7778\n",
            "Epoch 67/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0870 - acc: 0.9719Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9800 - acc: 0.7886\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0834 - acc: 0.9728 - val_loss: 1.1935 - val_acc: 0.7886\n",
            "Epoch 68/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0995 - acc: 0.9586Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.7966 - acc: 0.8293\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0990 - acc: 0.9586 - val_loss: 0.8528 - val_acc: 0.8293\n",
            "Epoch 69/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0665 - acc: 0.9732Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7465 - acc: 0.8469\n",
            "15/15 [==============================] - 6s 368ms/step - loss: 0.0691 - acc: 0.9722 - val_loss: 0.7639 - val_acc: 0.8469\n",
            "Epoch 70/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0828 - acc: 0.9707Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.6810 - acc: 0.8672\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0799 - acc: 0.9717 - val_loss: 0.6874 - val_acc: 0.8672\n",
            "Epoch 71/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0758 - acc: 0.9750Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.3618 - acc: 0.8875\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 0.0746 - acc: 0.9739 - val_loss: 0.4069 - val_acc: 0.8875\n",
            "Epoch 72/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0850 - acc: 0.9590Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.9476 - acc: 0.8469\n",
            "15/15 [==============================] - 5s 359ms/step - loss: 0.0847 - acc: 0.9586 - val_loss: 0.9389 - val_acc: 0.8469\n",
            "Epoch 73/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1062 - acc: 0.9641Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4113 - acc: 0.8997\n",
            "15/15 [==============================] - 5s 359ms/step - loss: 0.1105 - acc: 0.9630 - val_loss: 0.3985 - val_acc: 0.8997\n",
            "Epoch 74/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0956 - acc: 0.9688Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.3137 - acc: 0.8076\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.0937 - acc: 0.9688 - val_loss: 1.1592 - val_acc: 0.8076\n",
            "Epoch 75/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0647 - acc: 0.9735Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9121 - acc: 0.8117\n",
            "15/15 [==============================] - 5s 354ms/step - loss: 0.0629 - acc: 0.9739 - val_loss: 0.8999 - val_acc: 0.8117\n",
            "Epoch 76/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0632 - acc: 0.9766Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.6668 - acc: 0.8198\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.0615 - acc: 0.9768 - val_loss: 0.6358 - val_acc: 0.8198\n",
            "Epoch 77/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0895 - acc: 0.9657Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.9374 - acc: 0.8130\n",
            "15/15 [==============================] - 5s 365ms/step - loss: 0.0914 - acc: 0.9651 - val_loss: 0.8880 - val_acc: 0.8130\n",
            "Epoch 78/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0777 - acc: 0.9723Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.7201 - acc: 0.8415\n",
            "15/15 [==============================] - 6s 369ms/step - loss: 0.0803 - acc: 0.9724 - val_loss: 0.7093 - val_acc: 0.8415\n",
            "Epoch 79/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0811 - acc: 0.9703Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0810 - acc: 0.8062\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.0784 - acc: 0.9706 - val_loss: 0.9929 - val_acc: 0.8062\n",
            "Epoch 80/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1031 - acc: 0.9614Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4070 - acc: 0.9214\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.1021 - acc: 0.9611 - val_loss: 0.2997 - val_acc: 0.9214\n",
            "Epoch 81/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0620 - acc: 0.9754Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 2.0290 - acc: 0.7683\n",
            "15/15 [==============================] - 5s 364ms/step - loss: 0.0620 - acc: 0.9749 - val_loss: 1.8209 - val_acc: 0.7683\n",
            "Epoch 82/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0567 - acc: 0.9766Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.2356 - acc: 0.9295\n",
            "15/15 [==============================] - 5s 366ms/step - loss: 0.0596 - acc: 0.9764 - val_loss: 0.2327 - val_acc: 0.9295\n",
            "Epoch 83/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0474 - acc: 0.9793Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.8142 - acc: 0.8469\n",
            "15/15 [==============================] - 6s 368ms/step - loss: 0.0473 - acc: 0.9793 - val_loss: 0.8182 - val_acc: 0.8469\n",
            "Epoch 84/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0576 - acc: 0.9766Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.4103 - acc: 0.7575\n",
            "15/15 [==============================] - 6s 385ms/step - loss: 0.0583 - acc: 0.9767 - val_loss: 1.2865 - val_acc: 0.7575\n",
            "Epoch 85/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0788 - acc: 0.9684Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3052 - acc: 0.8821\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0766 - acc: 0.9691 - val_loss: 0.4127 - val_acc: 0.8821\n",
            "Epoch 86/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1240 - acc: 0.9520Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 3.1949 - acc: 0.7317\n",
            "15/15 [==============================] - 5s 354ms/step - loss: 0.1228 - acc: 0.9517 - val_loss: 3.2165 - val_acc: 0.7317\n",
            "Epoch 87/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0826 - acc: 0.9692Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 3.3120 - acc: 0.7317\n",
            "15/15 [==============================] - 5s 358ms/step - loss: 0.0800 - acc: 0.9699 - val_loss: 3.3835 - val_acc: 0.7317\n",
            "Epoch 88/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0818 - acc: 0.9713Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.4020 - acc: 0.7466\n",
            "15/15 [==============================] - 5s 343ms/step - loss: 0.0808 - acc: 0.9711 - val_loss: 1.4516 - val_acc: 0.7466\n",
            "Epoch 89/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0733 - acc: 0.9710Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.5346 - acc: 0.7493\n",
            "15/15 [==============================] - 6s 380ms/step - loss: 0.0710 - acc: 0.9722 - val_loss: 1.6290 - val_acc: 0.7493\n",
            "Epoch 90/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0563 - acc: 0.9793Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.7362 - acc: 0.8442\n",
            "15/15 [==============================] - 5s 364ms/step - loss: 0.0540 - acc: 0.9808 - val_loss: 0.6771 - val_acc: 0.8442\n",
            "Epoch 91/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0691 - acc: 0.9785Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5505 - acc: 0.9051\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 0.0652 - acc: 0.9793 - val_loss: 0.4772 - val_acc: 0.9051\n",
            "Epoch 92/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0747 - acc: 0.9750Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.7855 - acc: 0.8875\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.0772 - acc: 0.9742 - val_loss: 0.6020 - val_acc: 0.8875\n",
            "Epoch 93/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0655 - acc: 0.9746Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.3625 - acc: 0.8875\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.0685 - acc: 0.9728 - val_loss: 0.3411 - val_acc: 0.8875\n",
            "Epoch 94/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0696 - acc: 0.9703Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3988 - acc: 0.8780\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.0715 - acc: 0.9691 - val_loss: 0.3890 - val_acc: 0.8780\n",
            "Epoch 95/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0520 - acc: 0.9793Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.8436 - acc: 0.8144\n",
            "15/15 [==============================] - 5s 349ms/step - loss: 0.0511 - acc: 0.9795 - val_loss: 1.2566 - val_acc: 0.8144\n",
            "Epoch 96/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0450 - acc: 0.9855Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3109 - acc: 0.9309\n",
            "15/15 [==============================] - 6s 379ms/step - loss: 0.0428 - acc: 0.9865 - val_loss: 0.2405 - val_acc: 0.9309\n",
            "Epoch 97/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0445 - acc: 0.9825Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4926 - acc: 0.8875\n",
            "15/15 [==============================] - 6s 375ms/step - loss: 0.0480 - acc: 0.9816 - val_loss: 0.4464 - val_acc: 0.8875\n",
            "Epoch 98/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0722 - acc: 0.9729Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1726 - acc: 0.7520\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.0727 - acc: 0.9718 - val_loss: 1.1343 - val_acc: 0.7520\n",
            "Epoch 99/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0676 - acc: 0.9762Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.4215 - acc: 0.8957\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.0712 - acc: 0.9746 - val_loss: 0.4076 - val_acc: 0.8957\n",
            "Epoch 100/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0833 - acc: 0.9696Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.3984 - acc: 0.8686\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.0810 - acc: 0.9699 - val_loss: 0.3526 - val_acc: 0.8686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oKT0Eh8HgWl",
        "colab_type": "code",
        "outputId": "ffa29788-cbde-4f0b-dca9-be6cddae9c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl2MdvcVisbic/wMmgzZl1ke0+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzt2QM6VHggA",
        "colab_type": "code",
        "outputId": "6852dd33-419f-4b14-b8d1-14665c75ab83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Calculating model accuracy\n",
            "123/123 [==============================] - 0s 2ms/sample - loss: 0.3489 - acc: 0.8686\n",
            "Test Accuracy: 86.85637712478638\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}