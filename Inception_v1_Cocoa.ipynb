{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception-v1 Cocoa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sulfika715/DeepLearning/blob/master/Inception_v1_Cocoa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACZiBVxhe3D0",
        "colab_type": "code",
        "outputId": "817f9860-a97d-442f-8618-4c2dff642276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyCo5SVMf7Ao",
        "colab_type": "code",
        "outputId": "6755538d-a867-4876-a4ef-94261f071a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gco4RHVUe-qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((224, 224))\n",
        "image_size = 0\n",
        "directory_root = '/content/drive/My Drive/Colab Notebooks/Tugas 3 Deep Learning/Dataset Coklat'\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOZstMK0e_K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_erY8WlfBLs",
        "colab_type": "code",
        "outputId": "f8a5a0f0-35d3-4a10-ff17-82843a5d4ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for cocoa_folder in root_dir :\n",
        "        cocoa_class_folder_list = listdir(f\"{directory_root}/{cocoa_folder}\")\n",
        "        \n",
        "        for class_folder in cocoa_class_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if class_folder == \".DS_Store\" :\n",
        "                cocoa_class_folder_list.remove(class_folder)\n",
        "\n",
        "        for cocoa_class_folder in cocoa_classs_folder_list:\n",
        "            print(f\"[INFO] Processing {cocoa_class_folder} ...\")\n",
        "            cocoa_class_image_list = listdir(f\"{directory_root}/{cocoa_folder}/{cocoa_class_folder}\")\n",
        "                \n",
        "            for single_cocoa_class_image in cocoa_class_image_list :\n",
        "                if single_cocoa_class_image == \".DS_Store\" :\n",
        "                    cocoa_class_image_list.remove(single_cocoa_class_image)\n",
        "\n",
        "            for image in cocoa_class_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{cocoa_folder}/{cocoa_class  _folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing Moldy_Cocoa ...\n",
            "[INFO] Processing Broken_Beans_Cocoa ...\n",
            "[INFO] Processing Fermented_Cocoa ...\n",
            "[INFO] Processing Unfermented_Cocoa ...\n",
            "[INFO] Processing Bean_Fraction_Cocoa ...\n",
            "[INFO] Processing Whole_Beans_Cocoa ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J261jyCMfD2i",
        "colab_type": "code",
        "outputId": "7d1f85f4-2c22-4bb8-c384-5440e52cec55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = len(image_list)\n",
        "image_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BytB3K6mfH3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liNF8L0TfJUi",
        "colab_type": "code",
        "outputId": "f4e6cf9a-ce6c-44a6-d366-54eb4db996f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bean_Fraction_Cocoa' 'Broken_Beans_Cocoa' 'Fermented_Cocoa'\n",
            " 'Moldy_Cocoa' 'Unfermented_Cocoa' 'Whole_Beans_Cocoa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKzy8dHbfLW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB90_wYfuMi-",
        "colab_type": "code",
        "outputId": "e0953bde-8e3e-4ce3-8362-10a0e446eefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qikdVbBWfNAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUu03gsKhn5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Inception Model\n",
        "\n",
        "# Impor paket yang diperlukan Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "# Inisialisasi Core\n",
        "kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "# Inisialisasi offset\n",
        "bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "\n",
        "# Fungsi yang menghasilkan Modul Inception\n",
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "\n",
        "    # Konvolusi 1 × 1\n",
        "    conv_1x1 = Conv2D(filters_1x1,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_1x1 = BatchNormalization()(conv_1x1)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 3x3\n",
        "    conv_3x3 = Conv2D(filters_3x3,\n",
        "                      (3, 3),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_3x3)\n",
        "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk reduksi dimensi Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce,\n",
        "                      (1, 1),\n",
        "                      padding='same',\n",
        "                      activation='relu')(x)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Konvolusi 5x5\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5),\n",
        "                      padding='same',\n",
        "                      activation='relu')(conv_5x5)\n",
        "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
        "\n",
        "    # Max pooling\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    # Konvolusi 1 × 1 untuk mencerna dimensi maksimum yang dikurangi\n",
        "    pool_proj = Conv2D(filters_pool_proj,\n",
        "                       (1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(pool_proj)\n",
        "    pool_proj = BatchNormalization()(pool_proj)\n",
        "\n",
        "    # Stack merge\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VGlDuXkhh1M",
        "colab_type": "code",
        "outputId": "7b38227e-89ad-48ba-e5a6-949055250262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Impor paket yang diperlukan\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Mendefinisikan GoogleNet / Inception-V1\n",
        "class GoogleNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, channel, classes):\n",
        "\n",
        "        input_layer = Input(shape=(width, height, channel))\n",
        "\n",
        "        # Inisialisasi inti\n",
        "        kernel_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        # Inisialisasi offset\n",
        "        bias_init = tf.keras.initializers.Constant(value=0.2)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (7, 7),\n",
        "                   padding='same',\n",
        "                   strides=(2, 2),\n",
        "                   activation='relu',\n",
        "                   name='conv_1_7x7/2')(input_layer)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(64,\n",
        "                   (1, 1),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2a_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Konvolusi\n",
        "        x = Conv2D(192,\n",
        "                   (3, 3),\n",
        "                   padding='same',\n",
        "                   strides=(1, 1),\n",
        "                   activation='relu',\n",
        "                   name='conv_2b_3x3/1')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=64,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=128,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=32,\n",
        "                             filters_pool_proj=32,\n",
        "                             name='inception_3a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=192,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=96,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_3b')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=192,\n",
        "                             filters_3x3_reduce=96,\n",
        "                             filters_3x3=208,\n",
        "                             filters_5x5_reduce=16,\n",
        "                             filters_5x5=48,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=160,\n",
        "                             filters_3x3_reduce=112,\n",
        "                             filters_3x3=224,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4b')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=128,\n",
        "                             filters_3x3_reduce=128,\n",
        "                             filters_3x3=256,\n",
        "                             filters_5x5_reduce=24,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4c')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=112,\n",
        "                             filters_3x3_reduce=144,\n",
        "                             filters_3x3=288,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=64,\n",
        "                             filters_pool_proj=64,\n",
        "                             name='inception_4d')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_4e')\n",
        "\n",
        "        # Max pooling\n",
        "        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=256,\n",
        "                             filters_3x3_reduce=160,\n",
        "                             filters_3x3=320,\n",
        "                             filters_5x5_reduce=32,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5a')\n",
        "\n",
        "        # Inception Module\n",
        "        x = inception_module(x,\n",
        "                             filters_1x1=384,\n",
        "                             filters_3x3_reduce=192,\n",
        "                             filters_3x3=384,\n",
        "                             filters_5x5_reduce=48,\n",
        "                             filters_5x5=128,\n",
        "                             filters_pool_proj=128,\n",
        "                             name='inception_5b')\n",
        "\n",
        "        # Global Avarage Pooling\n",
        "        x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "        # Random inactivation\n",
        "        x = Dropout(0.40)(x)\n",
        "\n",
        "        # Full connection/output\n",
        "        x = Dense(classes, activation='softmax', name='output')(x)\n",
        "\n",
        "        # Create GoogleNet model\n",
        "        # return Model(input_layer, [x, x1, x2], name='inception_v1')\n",
        "        return Model(input_layer, x, name='inception_v1')\n",
        "\n",
        "\n",
        "# Test GoogleNet class instantiation and output summary information of GoogleNet model\n",
        "if __name__ == \"__main__\":\n",
        "    model = GoogleNet.build(width=224, height=224, channel=3, classes=6)\n",
        "    print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1_7x7/2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv_1_7x7/2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_1_3x3/2 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_2a_3x3/1 (Conv2D)          (None, 56, 56, 64)   4160        max_pool_1_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv_2a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_2b_3x3/1 (Conv2D)          (None, 56, 56, 192)  110784      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 192)  768         conv_2b_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_3x3/2 (MaxPooling2D) (None, 28, 28, 192)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 96)   18528       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 16)   3088        max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 96)   384         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 28, 28, 192)  0           max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 64)   12352       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 128)  110720      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 32)   12832       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 32)   6176        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 28, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 28, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a (Concatenate)      (None, 28, 28, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 32)   8224        inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 128)  32896       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 192)  221376      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 96)   76896       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 192)  768         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 96)   384         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b (Concatenate)      (None, 28, 28, 480)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_3_3x3/2 (MaxPooling2D) (None, 14, 14, 480)  0           inception_3b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 14, 14, 96)   46176       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 16)   7696        max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 96)   384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 480)  0           max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 14, 14, 192)  92352       max_pool_3_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 208)  179920      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 48)   19248       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 192)  768         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 208)  832         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 48)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_15[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 112)  57456       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 24)   12312       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 14, 14, 112)  448         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 24)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 160)  82080       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 224)  226016      batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 14, 14, 160)  640         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 14, 14, 224)  896         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4b (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_21[0][0]     \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 24)   12312       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 14, 14, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 24)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 128)  65664       inception_4b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 256)  295168      batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 14, 14, 64)   38464       batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 128)  512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 64)   256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 64)   256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4c (Concatenate)      (None, 14, 14, 512)  0           batch_normalization_27[0][0]     \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 144)  73872       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 32)   16416       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 144)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 512)  0           inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 112)  57456       inception_4c[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 288)  373536      batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 64)   51264       batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 112)  448         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 288)  1152        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 64)   256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4d (Concatenate)      (None, 14, 14, 528)  0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 160)  84640       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 32)   16928       inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 160)  640         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 32)   128         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 528)  0           inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 256)  135424      inception_4d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 320)  461120      batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 128)  102528      batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 320)  1280        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 14, 14, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e (Concatenate)      (None, 14, 14, 832)  0           batch_normalization_39[0][0]     \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_4_3x3/2 (MaxPooling2D) (None, 7, 7, 832)    0           inception_4e[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 160)    133280      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 32)     26656       max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    640         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 32)     128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 832)    0           max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 256)    213248      max_pool_4_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 320)    461120      batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 128)    102528      batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 320)    1280        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 128)    512         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 128)    512         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a (Concatenate)      (None, 7, 7, 832)    0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    159936      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 48)     39984       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 192)    768         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 48)     192         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 832)    0           inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 384)    319872      inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 384)    663936      batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 128)    153728      batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 384)    1536        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 384)    1536        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 128)    512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 128)    512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b (Concatenate)      (None, 7, 7, 1024)   0           batch_normalization_51[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool_5_3x3/1 (GlobalAverage (None, 1024)         0           inception_5b[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           avg_pool_5_3x3/1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 6)            6150        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,008,822\n",
            "Trainable params: 5,994,262\n",
            "Non-trainable params: 14,560\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhwBbSRnfYtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qJD2eg1cXBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='Adam',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ckx2N-KfVlr",
        "colab_type": "code",
        "outputId": "115833a5-9595-4dec-866c-a61a6cea8747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    validation_steps=1200// BS,\n",
        "    max_queue_size=BS*2,\n",
        "    verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "14/15 [===========================>..] - ETA: 1s - loss: 0.4866 - acc: 0.8419Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 2s 13ms/sample - loss: 0.4823 - acc: 0.8333\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.4971 - acc: 0.8396 - val_loss: 0.4701 - val_acc: 0.8333\n",
            "Epoch 2/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.4423 - acc: 0.8502Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5661 - acc: 0.7561\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.4304 - acc: 0.8520 - val_loss: 0.5426 - val_acc: 0.7561\n",
            "Epoch 3/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.3005 - acc: 0.8716Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 3.0727 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.2971 - acc: 0.8740 - val_loss: 3.0948 - val_acc: 0.7154\n",
            "Epoch 4/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2429 - acc: 0.8915Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 2.3799 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.2400 - acc: 0.8936 - val_loss: 2.3482 - val_acc: 0.7154\n",
            "Epoch 5/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2167 - acc: 0.9025Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.5039 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 345ms/step - loss: 0.2121 - acc: 0.9052 - val_loss: 1.4861 - val_acc: 0.7154\n",
            "Epoch 6/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2264 - acc: 0.9067Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1934 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.2281 - acc: 0.9067 - val_loss: 1.2005 - val_acc: 0.7154\n",
            "Epoch 7/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2165 - acc: 0.9027Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.2799 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 319ms/step - loss: 0.2199 - acc: 0.9018 - val_loss: 1.2781 - val_acc: 0.7154\n",
            "Epoch 8/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1957 - acc: 0.9092Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7586 - acc: 0.7304\n",
            "15/15 [==============================] - 5s 345ms/step - loss: 0.2016 - acc: 0.9087 - val_loss: 0.8315 - val_acc: 0.7304\n",
            "Epoch 9/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1820 - acc: 0.9247Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5587 - acc: 0.8238\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.1809 - acc: 0.9248 - val_loss: 0.5865 - val_acc: 0.8238\n",
            "Epoch 10/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1842 - acc: 0.9329Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.9067 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 342ms/step - loss: 0.1824 - acc: 0.9325 - val_loss: 1.8518 - val_acc: 0.7154\n",
            "Epoch 11/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1918 - acc: 0.9254Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.6790 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.1890 - acc: 0.9267 - val_loss: 1.6585 - val_acc: 0.7154\n",
            "Epoch 12/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2225 - acc: 0.9091Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 1s 5ms/sample - loss: 0.8786 - acc: 0.7154\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.2180 - acc: 0.9098 - val_loss: 0.8291 - val_acc: 0.7154\n",
            "Epoch 13/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1650 - acc: 0.9315Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.6276 - acc: 0.7358\n",
            "15/15 [==============================] - 5s 337ms/step - loss: 0.1630 - acc: 0.9321 - val_loss: 0.6351 - val_acc: 0.7358\n",
            "Epoch 14/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1488 - acc: 0.9446Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9065 - acc: 0.7304\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.1450 - acc: 0.9455 - val_loss: 0.9682 - val_acc: 0.7304\n",
            "Epoch 15/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1755 - acc: 0.9243Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0852 - acc: 0.7195\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.1717 - acc: 0.9256 - val_loss: 1.0818 - val_acc: 0.7195\n",
            "Epoch 16/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1525 - acc: 0.9333Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5565 - acc: 0.7656\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.1494 - acc: 0.9354 - val_loss: 0.5601 - val_acc: 0.7656\n",
            "Epoch 17/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1603 - acc: 0.9348Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8120 - acc: 0.7304\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.1537 - acc: 0.9375 - val_loss: 0.8497 - val_acc: 0.7304\n",
            "Epoch 18/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1432 - acc: 0.9469Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9722 - acc: 0.7669\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.1484 - acc: 0.9444 - val_loss: 0.9142 - val_acc: 0.7669\n",
            "Epoch 19/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1478 - acc: 0.9344Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7717 - acc: 0.8008\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.1500 - acc: 0.9339 - val_loss: 0.7818 - val_acc: 0.8008\n",
            "Epoch 20/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1540 - acc: 0.9412Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7883 - acc: 0.7791\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.1550 - acc: 0.9406 - val_loss: 0.7726 - val_acc: 0.7791\n",
            "Epoch 21/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1154 - acc: 0.9462Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.6221 - acc: 0.8089\n",
            "15/15 [==============================] - 5s 318ms/step - loss: 0.1212 - acc: 0.9437 - val_loss: 0.5549 - val_acc: 0.8089\n",
            "Epoch 22/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1335 - acc: 0.9464Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0396 - acc: 0.7805\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.1311 - acc: 0.9476 - val_loss: 0.9254 - val_acc: 0.7805\n",
            "Epoch 23/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1696 - acc: 0.9336Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1896 - acc: 0.7602\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.1663 - acc: 0.9346 - val_loss: 1.0181 - val_acc: 0.7602\n",
            "Epoch 24/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1381 - acc: 0.9487Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0068 - acc: 0.7778\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.1364 - acc: 0.9502 - val_loss: 0.9056 - val_acc: 0.7778\n",
            "Epoch 25/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1531 - acc: 0.9397Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.6135 - acc: 0.7805\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.1497 - acc: 0.9410 - val_loss: 1.6067 - val_acc: 0.7805\n",
            "Epoch 26/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1611 - acc: 0.9387Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0758 - acc: 0.8076\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.1786 - acc: 0.9346 - val_loss: 0.8362 - val_acc: 0.8076\n",
            "Epoch 27/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.2014 - acc: 0.9226Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0077 - acc: 0.7967\n",
            "15/15 [==============================] - 5s 343ms/step - loss: 0.1956 - acc: 0.9240 - val_loss: 0.9280 - val_acc: 0.7967\n",
            "Epoch 28/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1852 - acc: 0.9270Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4840 - acc: 0.8496\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.1817 - acc: 0.9281 - val_loss: 0.4629 - val_acc: 0.8496\n",
            "Epoch 29/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1492 - acc: 0.9383Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9833 - acc: 0.8523\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.1470 - acc: 0.9401 - val_loss: 0.9393 - val_acc: 0.8523\n",
            "Epoch 30/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1236 - acc: 0.9489Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3609 - acc: 0.9038\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.1209 - acc: 0.9499 - val_loss: 0.3457 - val_acc: 0.9038\n",
            "Epoch 31/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1310 - acc: 0.9481Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0499 - acc: 0.7954\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.1271 - acc: 0.9503 - val_loss: 1.0332 - val_acc: 0.7954\n",
            "Epoch 32/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1455 - acc: 0.9407Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4070 - acc: 0.8821\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.1469 - acc: 0.9405 - val_loss: 0.3537 - val_acc: 0.8821\n",
            "Epoch 33/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1317 - acc: 0.9465Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8557 - acc: 0.8388\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.1361 - acc: 0.9455 - val_loss: 0.7844 - val_acc: 0.8388\n",
            "Epoch 34/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1444 - acc: 0.9450Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0227 - acc: 0.8144\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.1397 - acc: 0.9463 - val_loss: 0.9359 - val_acc: 0.8144\n",
            "Epoch 35/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1083 - acc: 0.9561Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1207 - acc: 0.7900\n",
            "15/15 [==============================] - 5s 341ms/step - loss: 0.1065 - acc: 0.9559 - val_loss: 1.0411 - val_acc: 0.7900\n",
            "Epoch 36/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1471 - acc: 0.9495Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.4523 - acc: 0.7724\n",
            "15/15 [==============================] - 5s 315ms/step - loss: 0.1470 - acc: 0.9482 - val_loss: 1.3807 - val_acc: 0.7724\n",
            "Epoch 37/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1086 - acc: 0.9587Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.6975 - acc: 0.7873\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.1157 - acc: 0.9549 - val_loss: 1.4131 - val_acc: 0.7873\n",
            "Epoch 38/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1227 - acc: 0.9516Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.2193 - acc: 0.7913\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.1207 - acc: 0.9524 - val_loss: 1.0641 - val_acc: 0.7913\n",
            "Epoch 39/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1267 - acc: 0.9503Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9230 - acc: 0.7751\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.1236 - acc: 0.9513 - val_loss: 0.8748 - val_acc: 0.7751\n",
            "Epoch 40/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1081 - acc: 0.9594Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0125 - acc: 0.7913\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.1100 - acc: 0.9579 - val_loss: 0.8571 - val_acc: 0.7913\n",
            "Epoch 41/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1531 - acc: 0.9438Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8681 - acc: 0.8035\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.1548 - acc: 0.9437 - val_loss: 0.7806 - val_acc: 0.8035\n",
            "Epoch 42/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1206 - acc: 0.9469Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1178 - acc: 0.7859\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.1209 - acc: 0.9466 - val_loss: 1.0769 - val_acc: 0.7859\n",
            "Epoch 43/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1124 - acc: 0.9520Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9917 - acc: 0.8279\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.1152 - acc: 0.9521 - val_loss: 0.8958 - val_acc: 0.8279\n",
            "Epoch 44/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0991 - acc: 0.9598Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1393 - acc: 0.8198\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.1051 - acc: 0.9583 - val_loss: 1.0768 - val_acc: 0.8198\n",
            "Epoch 45/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1549 - acc: 0.9473Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.3100 - acc: 0.7778\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.1511 - acc: 0.9488 - val_loss: 1.2926 - val_acc: 0.7778\n",
            "Epoch 46/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1105 - acc: 0.9594Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0101 - acc: 0.8008\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.1106 - acc: 0.9590 - val_loss: 0.9665 - val_acc: 0.8008\n",
            "Epoch 47/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1114 - acc: 0.9610Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.4983 - acc: 0.8252\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.1134 - acc: 0.9604 - val_loss: 1.0884 - val_acc: 0.8252\n",
            "Epoch 48/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0989 - acc: 0.9606Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0921 - acc: 0.8008\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.1036 - acc: 0.9587 - val_loss: 1.0179 - val_acc: 0.8008\n",
            "Epoch 49/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1483 - acc: 0.9477Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0316 - acc: 0.7913\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.1431 - acc: 0.9492 - val_loss: 0.9876 - val_acc: 0.7913\n",
            "Epoch 50/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1085 - acc: 0.9561Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.0054 - acc: 0.8022\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.1157 - acc: 0.9557 - val_loss: 0.9519 - val_acc: 0.8022\n",
            "Epoch 51/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1248 - acc: 0.9493Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9274 - acc: 0.7995\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.1262 - acc: 0.9495 - val_loss: 0.9072 - val_acc: 0.7995\n",
            "Epoch 52/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1187 - acc: 0.9561Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 0.9436 - acc: 0.7466\n",
            "15/15 [==============================] - 5s 342ms/step - loss: 0.1167 - acc: 0.9564 - val_loss: 1.0384 - val_acc: 0.7466\n",
            "Epoch 53/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0881 - acc: 0.9621Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0196 - acc: 0.7371\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.0858 - acc: 0.9633 - val_loss: 0.8953 - val_acc: 0.7371\n",
            "Epoch 54/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1029 - acc: 0.9594Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.7031 - acc: 0.8198\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.1094 - acc: 0.9568 - val_loss: 0.6454 - val_acc: 0.8198\n",
            "Epoch 55/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0826 - acc: 0.9728Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9135 - acc: 0.8238\n",
            "15/15 [==============================] - 5s 349ms/step - loss: 0.0852 - acc: 0.9722 - val_loss: 0.8495 - val_acc: 0.8238\n",
            "Epoch 56/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1394 - acc: 0.9528Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9709 - acc: 0.7900\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.1342 - acc: 0.9532 - val_loss: 0.8856 - val_acc: 0.7900\n",
            "Epoch 57/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1014 - acc: 0.9621Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.6937 - acc: 0.8211\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.1010 - acc: 0.9622 - val_loss: 0.5838 - val_acc: 0.8211\n",
            "Epoch 58/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1543 - acc: 0.9430Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1767 - acc: 0.7412\n",
            "15/15 [==============================] - 5s 340ms/step - loss: 0.1514 - acc: 0.9441 - val_loss: 1.0492 - val_acc: 0.7412\n",
            "Epoch 59/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1369 - acc: 0.9403Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4883 - acc: 0.8469\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.1338 - acc: 0.9426 - val_loss: 0.4957 - val_acc: 0.8469\n",
            "Epoch 60/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1123 - acc: 0.9590Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.8965 - acc: 0.7344\n",
            "15/15 [==============================] - 5s 341ms/step - loss: 0.1114 - acc: 0.9586 - val_loss: 1.8417 - val_acc: 0.7344\n",
            "Epoch 61/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0963 - acc: 0.9680Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9161 - acc: 0.7873\n",
            "15/15 [==============================] - 5s 337ms/step - loss: 0.0997 - acc: 0.9659 - val_loss: 0.7758 - val_acc: 0.7873\n",
            "Epoch 62/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1003 - acc: 0.9559Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0240 - acc: 0.7995\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.0990 - acc: 0.9557 - val_loss: 1.0009 - val_acc: 0.7995\n",
            "Epoch 63/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0759 - acc: 0.9707Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.8216 - acc: 0.8198\n",
            "15/15 [==============================] - 5s 337ms/step - loss: 0.0836 - acc: 0.9673 - val_loss: 1.6925 - val_acc: 0.8198\n",
            "Epoch 64/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0773 - acc: 0.9696Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.4687 - acc: 0.8333\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.0789 - acc: 0.9695 - val_loss: 1.3548 - val_acc: 0.8333\n",
            "Epoch 65/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0910 - acc: 0.9629Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1212 - acc: 0.8252\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.0884 - acc: 0.9644 - val_loss: 1.1129 - val_acc: 0.8252\n",
            "Epoch 66/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1073 - acc: 0.9559Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.6550 - acc: 0.8388\n",
            "15/15 [==============================] - 5s 334ms/step - loss: 0.1050 - acc: 0.9568 - val_loss: 0.5218 - val_acc: 0.8388\n",
            "Epoch 67/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0816 - acc: 0.9669Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8264 - acc: 0.8306\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0790 - acc: 0.9681 - val_loss: 0.7869 - val_acc: 0.8306\n",
            "Epoch 68/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1071 - acc: 0.9647Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1503 - acc: 0.8320\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.1044 - acc: 0.9635 - val_loss: 1.0562 - val_acc: 0.8320\n",
            "Epoch 69/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0937 - acc: 0.9668Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1901 - acc: 0.8157\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.0890 - acc: 0.9691 - val_loss: 1.1198 - val_acc: 0.8157\n",
            "Epoch 70/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0773 - acc: 0.9688Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.6722 - acc: 0.8266\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.0770 - acc: 0.9681 - val_loss: 0.6025 - val_acc: 0.8266\n",
            "Epoch 71/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0681 - acc: 0.9723Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4248 - acc: 0.8835\n",
            "15/15 [==============================] - 5s 334ms/step - loss: 0.0661 - acc: 0.9731 - val_loss: 0.3498 - val_acc: 0.8835\n",
            "Epoch 72/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0723 - acc: 0.9778Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.6262 - acc: 0.8415\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0689 - acc: 0.9787 - val_loss: 0.5925 - val_acc: 0.8415\n",
            "Epoch 73/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1166 - acc: 0.9586Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4520 - acc: 0.8089\n",
            "15/15 [==============================] - 5s 337ms/step - loss: 0.1217 - acc: 0.9561 - val_loss: 0.4977 - val_acc: 0.8089\n",
            "Epoch 74/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0927 - acc: 0.9673Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.4971 - acc: 0.8767\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0967 - acc: 0.9667 - val_loss: 0.5266 - val_acc: 0.8767\n",
            "Epoch 75/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0822 - acc: 0.9704Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 2.1029 - acc: 0.7669\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.0806 - acc: 0.9703 - val_loss: 1.9980 - val_acc: 0.7669\n",
            "Epoch 76/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0743 - acc: 0.9706Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.5542 - acc: 0.7507\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.0931 - acc: 0.9691 - val_loss: 1.2630 - val_acc: 0.7507\n",
            "Epoch 77/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1085 - acc: 0.9554Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1998 - acc: 0.8550\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.1099 - acc: 0.9542 - val_loss: 1.2493 - val_acc: 0.8550\n",
            "Epoch 78/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0821 - acc: 0.9703Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0150 - acc: 0.8780\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.0805 - acc: 0.9706 - val_loss: 0.8547 - val_acc: 0.8780\n",
            "Epoch 79/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0916 - acc: 0.9692Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3612 - acc: 0.9295\n",
            "15/15 [==============================] - 5s 336ms/step - loss: 0.0888 - acc: 0.9699 - val_loss: 0.2707 - val_acc: 0.9295\n",
            "Epoch 80/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1017 - acc: 0.9649Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8595 - acc: 0.8577\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.1009 - acc: 0.9637 - val_loss: 0.8332 - val_acc: 0.8577\n",
            "Epoch 81/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0732 - acc: 0.9692Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.5678 - acc: 0.8184\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.0713 - acc: 0.9706 - val_loss: 1.5559 - val_acc: 0.8184\n",
            "Epoch 82/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0650 - acc: 0.9762Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1642 - acc: 0.7818\n",
            "15/15 [==============================] - 5s 340ms/step - loss: 0.0656 - acc: 0.9749 - val_loss: 1.0744 - val_acc: 0.7818\n",
            "Epoch 83/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0811 - acc: 0.9684Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8027 - acc: 0.8550\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0790 - acc: 0.9681 - val_loss: 0.7877 - val_acc: 0.8550\n",
            "Epoch 84/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0746 - acc: 0.9725Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.2552 - acc: 0.7344\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0754 - acc: 0.9718 - val_loss: 1.2448 - val_acc: 0.7344\n",
            "Epoch 85/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0872 - acc: 0.9702Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5509 - acc: 0.8428\n",
            "15/15 [==============================] - 5s 358ms/step - loss: 0.0924 - acc: 0.9677 - val_loss: 0.4971 - val_acc: 0.8428\n",
            "Epoch 86/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1105 - acc: 0.9567Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8384 - acc: 0.7873\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.1112 - acc: 0.9568 - val_loss: 0.7585 - val_acc: 0.7873\n",
            "Epoch 87/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0975 - acc: 0.9680Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1109 - acc: 0.7995\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0960 - acc: 0.9688 - val_loss: 1.0845 - val_acc: 0.7995\n",
            "Epoch 88/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0810 - acc: 0.9721Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1397 - acc: 0.8211\n",
            "15/15 [==============================] - 5s 345ms/step - loss: 0.0780 - acc: 0.9729 - val_loss: 1.1998 - val_acc: 0.8211\n",
            "Epoch 89/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0898 - acc: 0.9672Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.3859 - acc: 0.8130\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.0893 - acc: 0.9673 - val_loss: 1.3352 - val_acc: 0.8130\n",
            "Epoch 90/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0624 - acc: 0.9742Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9659 - acc: 0.8523\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.0596 - acc: 0.9753 - val_loss: 0.9654 - val_acc: 0.8523\n",
            "Epoch 91/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0957 - acc: 0.9725Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3770 - acc: 0.9079\n",
            "15/15 [==============================] - 5s 318ms/step - loss: 0.0969 - acc: 0.9707 - val_loss: 0.3467 - val_acc: 0.9079\n",
            "Epoch 92/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0800 - acc: 0.9710Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.1487 - acc: 0.9553\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.0782 - acc: 0.9722 - val_loss: 0.1157 - val_acc: 0.9553\n",
            "Epoch 93/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0684 - acc: 0.9735Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5704 - acc: 0.8645\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.0695 - acc: 0.9720 - val_loss: 0.5208 - val_acc: 0.8645\n",
            "Epoch 94/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0719 - acc: 0.9731Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.1494 - acc: 0.7791\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.0689 - acc: 0.9742 - val_loss: 1.0429 - val_acc: 0.7791\n",
            "Epoch 95/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0834 - acc: 0.9703Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.8292 - acc: 0.8509\n",
            "15/15 [==============================] - 5s 338ms/step - loss: 0.0823 - acc: 0.9710 - val_loss: 0.8002 - val_acc: 0.8509\n",
            "Epoch 96/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.1153 - acc: 0.9637Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3029 - acc: 0.9241\n",
            "15/15 [==============================] - 5s 342ms/step - loss: 0.1139 - acc: 0.9630 - val_loss: 0.2177 - val_acc: 0.9241\n",
            "Epoch 97/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0739 - acc: 0.9707Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.3622 - acc: 0.8984\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.0767 - acc: 0.9706 - val_loss: 0.3359 - val_acc: 0.8984\n",
            "Epoch 98/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0994 - acc: 0.9707Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.9099 - acc: 0.8523\n",
            "15/15 [==============================] - 5s 334ms/step - loss: 0.0954 - acc: 0.9717 - val_loss: 0.9277 - val_acc: 0.8523\n",
            "Epoch 99/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0675 - acc: 0.9728Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 0.5576 - acc: 0.8740\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.0689 - acc: 0.9726 - val_loss: 0.5873 - val_acc: 0.8740\n",
            "Epoch 100/100\n",
            "14/15 [===========================>..] - ETA: 0s - loss: 0.0726 - acc: 0.9655Epoch 1/100\n",
            "123/15 [=====================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0417 - acc: 0.7696\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0764 - acc: 0.9646 - val_loss: 1.0076 - val_acc: 0.7696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAWbuE97FVNG",
        "colab_type": "code",
        "outputId": "4a24ad54-991b-4a8b-f9d8-7fae93f127e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqI4HBV6RVEUh/N/FdxZNyyEvX4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsLKAuO9ffGw",
        "colab_type": "code",
        "outputId": "61573570-fd61-4f0e-d190-b12d5d0798e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Calculating model accuracy\n",
            "123/123 [==============================] - 0s 2ms/sample - loss: 1.0048 - acc: 0.7696\n",
            "Test Accuracy: 76.96477174758911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWQ0P9YEfgss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to disk\n",
        "#print(\"[INFO] Saving model...\")\n",
        "#pickle.dump(model,open('cnn_model.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}